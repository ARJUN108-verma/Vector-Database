{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMOTjwvSA+1CGyJpb+aKc8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARJUN108-verma/Vector-Database/blob/main/11_Using_BERT_Embedding_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using BERT Embedding Algorithm:-"
      ],
      "metadata": {
        "id": "sB9kLRzoV54Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Indexing: Creating a Chroma Vectorstore"
      ],
      "metadata": {
        "id": "S42vuWY5WL7l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82_evo9rVrlN"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1w44F6b8WY1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = pd.read_csv(\"/content/course_section_descriptions.csv\", encoding='ANSI')"
      ],
      "metadata": {
        "id": "gRYOBJNDWchZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "uF4_KtMZWqmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'files' DataFrame is already defined and includes necessary columns\n",
        "\n",
        "# Define weights for different text components\n",
        "weight_course_name = 5\n",
        "weight_section_name = 3\n",
        "weight_section_description = 2\n",
        "weight_other = 1  # For other components like course technology and course description\n",
        "\n",
        "# Create a unique identifier for each section combining course_id and section_id\n",
        "files['unique_id'] = files['course_id'].astype(str) + '-' + files['section_id'].astype(str)\n",
        "\n",
        "# Create metadata for each section\n",
        "files['metadata'] = files.apply(lambda row: {\n",
        "    \"course_name\": row['course_name'],\n",
        "    \"section_name\": row['section_name'],\n",
        "    \"section_description\": row['section_description']\n",
        "}, axis=1)"
      ],
      "metadata": {
        "id": "6Qnde4e2Wn7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(row):\n",
        "    # Encode individual components\n",
        "    emb_course_name = model.encode(row['course_name'], show_progress_bar=False) * weight_course_name\n",
        "    emb_section_name = model.encode(row['section_name'], show_progress_bar=False) * weight_section_name\n",
        "    emb_section_description = model.encode(row['section_description'], show_progress_bar=False) * weight_section_description\n",
        "    emb_course_tech = model.encode(row['course_technology'], show_progress_bar=False) * weight_other\n",
        "    emb_course_desc = model.encode(row['course_description'], show_progress_bar=False) * weight_other\n",
        "\n",
        "    # Combine embeddings by averaging them\n",
        "    combined_embedding = (emb_course_name + emb_section_name + emb_section_description + emb_course_tech + emb_course_desc) / (weight_course_name + weight_section_name + weight_section_description + 2 * weight_other)\n",
        "    return combined_embedding\n",
        "\n",
        "# Initialize the model\n",
        "model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
        "\n",
        "# Apply the function to create weighted embeddings\n",
        "files['embedding'] = files.apply(create_embeddings, axis=1)\n"
      ],
      "metadata": {
        "id": "jCtDPhGxW0cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding :-"
      ],
      "metadata": {
        "id": "U1Ft9bItW5J7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig1oSF5MW0Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRKgKmfjW_rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Pinecone Index"
      ],
      "metadata": {
        "id": "IjeA2GxLXAXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec"
      ],
      "metadata": {
        "id": "pIUcYl-NXC8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "UVI0381NXIaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv(find_dotenv(), override = True)"
      ],
      "metadata": {
        "id": "5CzOOLtSXMFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "pc = Pinecone(api_key = os.environ.get(\"PINECONE_API_KEY\"), environment = os.environ.get(\"PINECONE_ENV\"))"
      ],
      "metadata": {
        "id": "YXW5VrKMXR5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(\"my-index\")"
      ],
      "metadata": {
        "id": "_bWHQbfFXVRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.delete(delete_all = True)"
      ],
      "metadata": {
        "id": "vxWaOIm_XWCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the vectors for upserting\n",
        "vectors_to_upsert = [(row['unique_id'], row['embedding'].tolist(), row['metadata']) for index, row in files.iterrows()]\n"
      ],
      "metadata": {
        "id": "VVmNFDcTXdGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Upsert data\n",
        "index.upsert(vectors=vectors_to_upsert)\n",
        "\n",
        "print(\"Data successfully upserted to Pinecone index.\")"
      ],
      "metadata": {
        "id": "qTGjxOgFXg1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you've already initialized and configured Pinecone and the model\n",
        "# If not, you need to run the initialization code provided earlier\n",
        "\n",
        "# Create the query embedding\n",
        "query = \"lasso\"\n",
        "query_embedding = model.encode(query, show_progress_bar=False).tolist()"
      ],
      "metadata": {
        "id": "mUslXsZCXnmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_results = index.query(\n",
        "   # namespace=\"my-index\",\n",
        "    vector=[query_embedding],\n",
        "    top_k=15,\n",
        "    include_metadata=True\n",
        ")"
      ],
      "metadata": {
        "id": "syeRoWWkXrg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint"
      ],
      "metadata": {
        "id": "QDjItDPzXvMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_threshold = 0.3"
      ],
      "metadata": {
        "id": "28tOZzaQXyAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming query_results are fetched and include metadata\n",
        "for match in query_results['matches']:\n",
        "    if match['score'] >= score_threshold:\n",
        "        course_details = match.get('metadata', {})\n",
        "        course_name = course_details.get('course_name', 'N/A')\n",
        "        section_name = course_details.get('section_name', 'N/A')\n",
        "        section_description = course_details.get('section_description', 'No description available')\n",
        "\n",
        "        pprint.pprint(f\"Matched item ID: {match['id']}, Score: {match['score']}\")\n",
        "        pprint.pprint(f\"Course: {course_name}\")\n",
        "        pprint.pprint(f\"Section: {section_name}, Description: {section_description}\", width = 100)\n",
        "       #pprint.pprint()"
      ],
      "metadata": {
        "id": "wcJ76-69X1fl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}